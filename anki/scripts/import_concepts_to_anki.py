#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°† concepts CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki
ä½¿ç”¨ AnkiConnect API å°†æ¦‚å¿µå¡ç‰‡æ·»åŠ åˆ° Anki
"""

import json
import csv
import os
import sys
import requests
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from config import (
    ANKI_CONNECT_URL,
    ANKI_MODEL_NAME,
    DECK_NAME_PREFIX,
    DEFAULT_TAGS,
    CONCEPTS_DECK_NAME_FORMAT,
    CONCEPTS_FIELD_MAPPING
)

# å¯¼å…¥ extract_concepts æ¨¡å—
try:
    # ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ—¶
    script_dir = Path(__file__).parent  # anki/scripts
    project_root = script_dir.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
    sys.path.insert(0, str(project_root))
    from llm.scripts.extract_concepts import process_csv_file as generate_concepts
except (ImportError, ModuleNotFoundError) as e:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥å¯¼å…¥
    try:
        sys.path.insert(0, str(Path(__file__).parent.parent.parent / "llm" / "scripts"))
        from extract_concepts import process_csv_file as generate_concepts
    except (ImportError, ModuleNotFoundError) as e2:
        # å¯¼å…¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ google-generativeaiï¼‰
        generate_concepts = None
        # ä¸åœ¨è¿™é‡Œæ‰“å°é”™è¯¯ï¼Œè®©è°ƒç”¨æ–¹å¤„ç†


class AnkiConnectClient:
    """AnkiConnect API å®¢æˆ·ç«¯"""
    
    def __init__(self, url: Optional[str] = None):
        """
        åˆå§‹åŒ– AnkiConnect å®¢æˆ·ç«¯
        
        Args:
            url: AnkiConnect API åœ°å€ï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ï¼‰
        """
        self.url = url or ANKI_CONNECT_URL
    
    def _invoke(self, action: str, **params) -> Dict:
        """
        è°ƒç”¨ AnkiConnect API
        
        Args:
            action: API åŠ¨ä½œåç§°
            **params: API å‚æ•°
        
        Returns:
            API å“åº”ç»“æœ
        """
        payload = {
            "action": action,
            "version": 6,
            "params": params
        }
        
        try:
            response = requests.post(self.url, json=payload, timeout=10)
            response.raise_for_status()
            result = response.json()
            
            if len(result) != 2:
                raise Exception(f"å“åº”æ ¼å¼é”™è¯¯: {result}")
            
            if result.get("error") is not None:
                raise Exception(f"AnkiConnect é”™è¯¯: {result['error']}")
            
            return result.get("result")
        
        except requests.exceptions.ConnectionError:
            raise Exception("æ— æ³•è¿æ¥åˆ° AnkiConnectã€‚è¯·ç¡®ä¿ Anki æ­£åœ¨è¿è¡Œï¼Œå¹¶ä¸”å·²å®‰è£… AnkiConnect æ’ä»¶ã€‚")
        except requests.exceptions.Timeout:
            raise Exception("AnkiConnect è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            raise Exception(f"è°ƒç”¨ AnkiConnect API å¤±è´¥: {e}")
    
    def get_model_field_names(self, model_name: str) -> List[str]:
        """
        è·å–å¡ç‰Œæ¨¡æ¿çš„å­—æ®µååˆ—è¡¨
        
        Args:
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
        
        Returns:
            å­—æ®µååˆ—è¡¨
        """
        return self._invoke("modelFieldNames", modelName=model_name)
    
    def add_note(self, deck_name: str, model_name: str, fields: Dict[str, str], tags: Optional[List[str]] = None) -> int:
        """
        æ·»åŠ å•å¼ å¡ç‰‡åˆ° Anki
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
            fields: å­—æ®µå­—å…¸ï¼ˆå­—æ®µå -> å­—æ®µå€¼ï¼‰
            tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ–°åˆ›å»ºçš„å¡ç‰‡ ID
        """
        note = {
            "deckName": deck_name,
            "modelName": model_name,
            "fields": fields,
            "tags": tags or []
        }
        result = self._invoke("addNote", note=note)
        return result
    
    def add_notes(self, notes: List[Dict]) -> List[Optional[int]]:
        """
        æ‰¹é‡æ·»åŠ å¡ç‰‡åˆ° Anki
        
        Args:
            notes: å¡ç‰‡åˆ—è¡¨ï¼Œæ¯ä¸ªå¡ç‰‡æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« deckName, modelName, fields, tags
        
        Returns:
            æ–°åˆ›å»ºçš„å¡ç‰‡ ID åˆ—è¡¨ï¼ˆå¦‚æœå¤±è´¥åˆ™ä¸º Noneï¼‰
        """
        result = self._invoke("addNotes", notes=notes)
        return result
    
    def find_notes(self, query: str) -> List[int]:
        """
        æŸ¥æ‰¾å¡ç‰‡
        
        Args:
            query: æŸ¥è¯¢å­—ç¬¦ä¸²
        
        Returns:
            å¡ç‰‡ ID åˆ—è¡¨
        """
        return self._invoke("findNotes", query=query)
    
    def deck_names(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å¡ç‰Œç»„åç§°åˆ—è¡¨
        
        Returns:
            å¡ç‰Œç»„åç§°åˆ—è¡¨
        """
        return self._invoke("deckNames")
    
    def create_deck(self, deck_name: str) -> int:
        """
        åˆ›å»ºå¡ç‰Œç»„
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
        
        Returns:
            å¡ç‰Œç»„ ID
        """
        return self._invoke("createDeck", deck=deck_name)
    
    def deck_exists(self, deck_name: str) -> bool:
        """
        æ£€æŸ¥å¡ç‰Œç»„æ˜¯å¦å­˜åœ¨
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
        
        Returns:
            å¦‚æœå­˜åœ¨è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        decks = self.deck_names()
        return deck_name in decks
    
    def ensure_deck_exists(self, deck_name: str) -> bool:
        """
        ç¡®ä¿å¡ç‰Œç»„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
        
        Returns:
            å¦‚æœæˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        if self.deck_exists(deck_name):
            return True
        
        try:
            self.create_deck(deck_name)
            return True
        except Exception as e:
            print(f"  âš ï¸  åˆ›å»ºå¡ç‰Œç»„å¤±è´¥: {e}")
            return False
    
    def find_duplicate_notes(self, deck_name: str, model_name: str, fields: Dict[str, str]) -> List[int]:
        """
        æŸ¥æ‰¾é‡å¤çš„å¡ç‰‡ï¼ˆåŸºäº Name å­—æ®µçš„å€¼ï¼Œå³æ¦‚å¿µè¯ï¼‰
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
            fields: å­—æ®µå­—å…¸
        
        Returns:
            é‡å¤å¡ç‰‡çš„ ID åˆ—è¡¨
        """
        # ä¼˜å…ˆä½¿ç”¨ Name å­—æ®µï¼ˆæ¦‚å¿µè¯ï¼‰æ¥æŸ¥æ‰¾é‡å¤å¡ç‰‡
        if not fields:
            return []
        
        # ä¼˜å…ˆä½¿ç”¨ Name å­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ®µ
        name_field_value = fields.get('Name', '')
        if not name_field_value:
            # å¦‚æœæ²¡æœ‰ Name å­—æ®µï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ®µ
            name_field_value = list(fields.values())[0] if fields else ""
        
        if not name_field_value:
            return []
        
        # æ„å»ºæŸ¥è¯¢ï¼šæŸ¥æ‰¾ç›¸åŒå¡ç‰Œç»„ã€ç›¸åŒæ¨¡æ¿ã€ç›¸åŒ Name å­—æ®µå€¼çš„å¡ç‰‡
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼ˆAnki æŸ¥è¯¢è¯­æ³•éœ€è¦è½¬ä¹‰å¼•å·ã€å†’å·ç­‰ï¼‰
        escaped_deck_name = deck_name.replace('"', '\\"').replace(':', '\\:')
        escaped_model_name = model_name.replace('"', '\\"')
        # è½¬ä¹‰æŸ¥è¯¢å€¼ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        escaped_field_value = name_field_value.replace('"', '\\"').replace('\\', '\\\\')
        
        # ä½¿ç”¨æ›´ç²¾ç¡®çš„æŸ¥è¯¢ï¼šdeck:å¡ç‰Œç»„å note:æ¨¡æ¿å "Nameå­—æ®µå€¼"
        # æ³¨æ„ï¼šAnki æŸ¥è¯¢ä¸­ï¼Œå­—æ®µåéœ€è¦ç”¨å¼•å·åŒ…è£¹ï¼Œå€¼ä¹Ÿéœ€è¦ç”¨å¼•å·åŒ…è£¹
        query = f'deck:"{escaped_deck_name}" note:"{escaped_model_name}" "Name:{escaped_field_value}"'
        try:
            notes = self.find_notes(query)
            # å¦‚æœä¸Šé¢çš„æŸ¥è¯¢æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´ç®€å•çš„æŸ¥è¯¢ï¼ˆåªåŸºäºå­—æ®µå€¼ï¼‰
            if not notes:
                query_simple = f'deck:"{escaped_deck_name}" note:"{escaped_model_name}" {escaped_field_value}'
                notes = self.find_notes(query_simple)
            return notes
        except Exception as e:
            # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆä¸é˜»æ­¢æ·»åŠ ï¼‰
            print(f"  âš ï¸  æŸ¥è¯¢é‡å¤å¡ç‰‡æ—¶å‡ºé”™: {e}")
            return []
    
    def sync(self) -> bool:
        """
        åŒæ­¥ Anki åˆ° AnkiWeb
        
        Returns:
            å¦‚æœæˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            # AnkiConnect çš„ sync API ä¼šè§¦å‘åŒæ­¥ï¼ŒæˆåŠŸæ—¶é€šå¸¸è¿”å› None
            # æ³¨æ„ï¼šsync æ˜¯å¼‚æ­¥æ“ä½œï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
            result = self._invoke("sync")
            # sync æ“ä½œæˆåŠŸæ—¶é€šå¸¸è¿”å› None æˆ–ç©ºå€¼
            # å³ä½¿è¿”å› None ä¹Ÿè®¤ä¸ºæ˜¯æˆåŠŸï¼ˆå› ä¸º sync æ˜¯å¼‚æ­¥çš„ï¼‰
            return True
        except Exception as e:
            error_msg = str(e)
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„åŒæ­¥é”™è¯¯
            if "authentication" in error_msg.lower() or "login" in error_msg.lower() or "not logged in" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: è¯·å…ˆåœ¨ Anki ä¸­ç™»å½• AnkiWeb è´¦å·")
                print(f"     æ“ä½œæ­¥éª¤ï¼šAnki -> æ–‡ä»¶ -> åŒæ­¥ -> ç™»å½• AnkiWeb")
            elif "already syncing" in error_msg.lower() or "sync in progress" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: Anki æ­£åœ¨åŒæ­¥ä¸­ï¼Œè¯·ç¨åå†è¯•")
            elif "network" in error_msg.lower() or "connection" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            else:
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: {error_msg}")
                print(f"     æç¤ºï¼šè¯·ç¡®ä¿å·²åœ¨ Anki ä¸­ç™»å½• AnkiWeb è´¦å·ï¼Œå¹¶ä¸”ç½‘ç»œè¿æ¥æ­£å¸¸")
            return False


def read_csv_file(csv_file: Path) -> List[Dict[str, str]]:
    """
    è¯»å– CSV æ–‡ä»¶
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
    
    Returns:
        æ•°æ®è¡Œåˆ—è¡¨
    """
    rows = []
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                rows.append(row)
        return rows
    except Exception as e:
        print(f"é”™è¯¯ï¼šè¯»å– CSV æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")
        return []


def get_book_title_from_concepts_csv(csv_file: Path) -> Optional[str]:
    """
    ä» concepts CSV æ–‡ä»¶ä¸­è·å–ä¹¦åï¼ˆä»ç¬¬ä¸€è¡Œçš„ source å­—æ®µï¼‰
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
    
    Returns:
        ä¹¦åï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    rows = read_csv_file(csv_file)
    if rows and 'source' in rows[0]:
        return rows[0]['source'].strip()
    return None


def get_chapter_name_mapping(book_id: str, project_root: Path) -> Dict[int, str]:
    """
    ä»ç¬”è®° CSV æ–‡ä»¶ä¸­è·å–ç« èŠ‚å·åˆ°ç« èŠ‚åç§°çš„æ˜ å°„
    
    Args:
        book_id: ä¹¦ç±ID
        project_root: é¡¹ç›®æ ¹ç›®å½•
    
    Returns:
        ç« èŠ‚å·åˆ°ç« èŠ‚åç§°çš„å­—å…¸
    """
    chapter_mapping = {}
    
    # å°è¯•ä» bookmarks CSV æ–‡ä»¶ä¸­è¯»å–ç« èŠ‚åç§°
    bookmarks_file = project_root / "wereader" / "output" / "bookmarks" / f"{book_id}.csv"
    if bookmarks_file.exists():
        try:
            with open(bookmarks_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    chapter_uid = row.get('chapterUid', '').strip()
                    chapter_name = row.get('chapterName', '').strip()
                    if chapter_uid and chapter_name:
                        try:
                            chapter_uid_int = int(chapter_uid)
                            if chapter_uid_int not in chapter_mapping:
                                chapter_mapping[chapter_uid_int] = chapter_name
                        except ValueError:
                            pass
        except Exception as e:
            print(f"  âš ï¸  è¯»å–ç« èŠ‚åç§°æ˜ å°„å¤±è´¥: {e}")
    
    return chapter_mapping


def format_chapter_range(chapter_range: str, chapter_mapping: Dict[int, str]) -> str:
    """
    å°†ç« èŠ‚èŒƒå›´å­—ç¬¦ä¸²ï¼ˆå¦‚ "191" æˆ– "191-197"ï¼‰è½¬æ¢ä¸º"ç« èŠ‚å·-ç« èŠ‚å"æ ¼å¼
    
    Args:
        chapter_range: ç« èŠ‚èŒƒå›´å­—ç¬¦ä¸²ï¼ˆå¦‚ "191" æˆ– "191-197"ï¼‰
        chapter_mapping: ç« èŠ‚å·åˆ°ç« èŠ‚åç§°çš„æ˜ å°„
    
    Returns:
        æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²ï¼ˆå¦‚ "191-èµèª‰" æˆ– "191-èµèª‰-197-æ€»ç»“"ï¼‰
    """
    if not chapter_range or not chapter_range.strip():
        return ""
    
    chapter_range = chapter_range.strip()
    
    # è§£æç« èŠ‚èŒƒå›´ï¼ˆå¯èƒ½æ˜¯å•ä¸ªç« èŠ‚å·æˆ–èŒƒå›´ï¼‰
    if '-' in chapter_range:
        # èŒƒå›´æ ¼å¼ï¼šå¦‚ "191-197"
        parts = chapter_range.split('-')
        if len(parts) == 2:
            try:
                start_chapter = int(parts[0].strip())
                end_chapter = int(parts[1].strip())
                start_name = chapter_mapping.get(start_chapter, f'ç« èŠ‚{start_chapter}')
                end_name = chapter_mapping.get(end_chapter, f'ç« èŠ‚{end_chapter}')
                return f"{start_chapter}-{start_name}-{end_chapter}-{end_name}"
            except ValueError:
                return chapter_range
        else:
            return chapter_range
    else:
        # å•ä¸ªç« èŠ‚å·ï¼šå¦‚ "191"
        try:
            chapter_num = int(chapter_range)
            chapter_name = chapter_mapping.get(chapter_num, f'ç« èŠ‚{chapter_num}')
            return f"{chapter_num}-{chapter_name}"
        except ValueError:
            return chapter_range


def map_csv_fields_to_anki_fields(csv_row: Dict[str, str], field_mapping: Dict[str, str], 
                                   chapter_mapping: Optional[Dict[int, str]] = None) -> Dict[str, str]:
    """
    å°† CSV è¡Œæ•°æ®æ˜ å°„åˆ° Anki å­—æ®µ
    
    Args:
        csv_row: CSV è¡Œæ•°æ®ï¼ˆå­—å…¸ï¼‰
        field_mapping: å­—æ®µæ˜ å°„å…³ç³»ï¼ˆCSV åˆ—å -> Anki å­—æ®µåï¼‰
        chapter_mapping: ç« èŠ‚å·åˆ°ç« èŠ‚åç§°çš„æ˜ å°„ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        Anki å­—æ®µå­—å…¸
    """
    anki_fields = {}
    
    for csv_field, anki_field in field_mapping.items():
        if csv_field in csv_row:
            value = csv_row[csv_field]
            
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯ definition å­—æ®µï¼ˆæ˜ å°„åˆ° AINotesï¼‰ï¼Œå»é™¤é¦–å°¾å¼•å·
            if csv_field == 'definition' and anki_field == 'AINotes':
                # å»é™¤å¼€å¤´å’Œç»“å°¾çš„å¼•å·ï¼ˆå•å¼•å·æˆ–åŒå¼•å·ï¼‰
                value = value.strip()
                if value.startswith('"') and value.endswith('"'):
                    value = value[1:-1]
                elif value.startswith("'") and value.endswith("'"):
                    value = value[1:-1]
                # ç¡®ä¿æ˜¯ HTML æ ¼å¼
                value = value.strip()
            
            # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœæ˜¯ chapterRange å­—æ®µï¼ˆæ˜ å°„åˆ° Referencesï¼‰ï¼Œè½¬æ¢ä¸º"ç« èŠ‚å·-ç« èŠ‚å"æ ¼å¼
            elif csv_field == 'chapterRange' and anki_field == 'References':
                if chapter_mapping:
                    value = format_chapter_range(value, chapter_mapping)
                else:
                    # å¦‚æœæ²¡æœ‰ç« èŠ‚æ˜ å°„ï¼Œä¿æŒåŸå€¼
                    value = value.strip()
            
            anki_fields[anki_field] = value
        else:
            # å¦‚æœ CSV ä¸­æ²¡æœ‰è¯¥å­—æ®µï¼Œè®¾ç½®ä¸ºç©ºå­—ç¬¦ä¸²
            anki_fields[anki_field] = ""
    
    return anki_fields


def import_csv_to_anki(csv_file: Path, anki_client: AnkiConnectClient, model_name: Optional[str] = None, 
                       field_mapping: Optional[Dict[str, str]] = None, dry_run: bool = False, sync: bool = False,
                       batch_size: int = 100):
    """
    å°† concepts CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        anki_client: AnkiConnect å®¢æˆ·ç«¯
        model_name: Anki å¡ç‰Œæ¨¡æ¿åç§°ï¼ˆé»˜è®¤: KWDictï¼‰
        field_mapping: å­—æ®µæ˜ å°„å…³ç³»ï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„ï¼‰
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä¸å®é™…æ·»åŠ å¡ç‰‡ï¼‰
        sync: æ˜¯å¦åŒæ­¥åˆ° AnkiWeb
        batch_size: æ‰¹é‡æ·»åŠ çš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 100ï¼‰
    """
    if field_mapping is None:
        field_mapping = CONCEPTS_FIELD_MAPPING
    
    if model_name is None:
        model_name = ANKI_MODEL_NAME
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ–‡ä»¶: {csv_file.name}")
    print(f"{'='*60}")
    
    # è¯»å– CSV æ–‡ä»¶
    rows = read_csv_file(csv_file)
    if not rows:
        print(f"âš ï¸  æ–‡ä»¶ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ï¼Œè·³è¿‡")
        return
    
    print(f"è¯»å–åˆ° {len(rows)} æ¡è®°å½•")
    
    # è·å–ä¹¦åï¼ˆä»ç¬¬ä¸€è¡Œçš„ source å­—æ®µï¼‰
    book_title = get_book_title_from_concepts_csv(csv_file)
    if not book_title:
        print(f"âš ï¸  æ— æ³•è·å–ä¹¦åï¼Œè·³è¿‡")
        return
    
    # ä»æ–‡ä»¶åä¸­æå– book_idï¼ˆæ ¼å¼ï¼š{book_id}_concepts.csvï¼‰
    book_id = None
    file_stem = csv_file.stem  # ä¾‹å¦‚ï¼š38894783_concepts
    if '_concepts' in file_stem:
        book_id = file_stem.split('_concepts')[0]
    elif '_' in file_stem:
        # å¦‚æœæ²¡æœ‰ _conceptsï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ªä¸‹åˆ’çº¿å‰çš„éƒ¨åˆ†
        book_id = file_stem.split('_')[0]
    
    # è·å–ç« èŠ‚åç§°æ˜ å°„
    chapter_mapping = {}
    if book_id:
        script_dir = Path(__file__).parent  # anki/scripts
        project_root = script_dir.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
        chapter_mapping = get_chapter_name_mapping(book_id, project_root)
        if chapter_mapping:
            print(f"âœ“ å·²åŠ è½½ {len(chapter_mapping)} ä¸ªç« èŠ‚åç§°æ˜ å°„")
    
    # æ„å»ºå¡ç‰Œç»„åç§°ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„æ ¼å¼ï¼‰
    deck_name = CONCEPTS_DECK_NAME_FORMAT.format(book_title=book_title)
    print(f"å¡ç‰Œç»„: {deck_name}")
    print(f"å¡ç‰Œæ¨¡æ¿: {model_name}")
    
    # ç¡®ä¿å¡ç‰Œç»„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    if not anki_client.deck_exists(deck_name):
        print(f"å¡ç‰Œç»„ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
        if anki_client.ensure_deck_exists(deck_name):
            print(f"âœ“ æˆåŠŸåˆ›å»ºå¡ç‰Œç»„: {deck_name}")
        else:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•åˆ›å»ºå¡ç‰Œç»„: {deck_name}")
            return
    else:
        print(f"âœ“ å¡ç‰Œç»„å·²å­˜åœ¨: {deck_name}")
    
    # éªŒè¯å¡ç‰Œæ¨¡æ¿æ˜¯å¦å­˜åœ¨
    try:
        field_names = anki_client.get_model_field_names(model_name)
        print(f"å¡ç‰Œæ¨¡æ¿å­—æ®µ: {', '.join(field_names)}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è·å–å¡ç‰Œæ¨¡æ¿ '{model_name}' çš„ä¿¡æ¯: {e}")
        return
    
    # éªŒè¯æ˜ å°„çš„å­—æ®µæ˜¯å¦å­˜åœ¨äºå¡ç‰Œæ¨¡æ¿ä¸­
    mapped_fields = set(field_mapping.values())
    missing_fields = mapped_fields - set(field_names)
    if missing_fields:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹æ˜ å°„çš„å­—æ®µåœ¨å¡ç‰Œæ¨¡æ¿ä¸­ä¸å­˜åœ¨: {', '.join(missing_fields)}")
    
    # å‡†å¤‡è¦æ·»åŠ çš„å¡ç‰‡
    notes_to_add = []
    skipped_count = 0
    duplicate_count = 0
    
    print(f"\næ£€æŸ¥é‡å¤å¡ç‰‡...")
    for i, row in enumerate(rows, 1):
        # æ˜ å°„å­—æ®µï¼ˆä¼ å…¥ç« èŠ‚æ˜ å°„ï¼‰
        anki_fields = map_csv_fields_to_anki_fields(row, field_mapping, chapter_mapping)
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µï¼ˆName å­—æ®µï¼Œå¯¹åº” conceptï¼‰
        if 'Name' in anki_fields and not anki_fields['Name'].strip():
            skipped_count += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é‡å¤å¡ç‰‡ï¼ˆåŸºäº Name å­—æ®µï¼Œå³ conceptï¼‰
        if 'Name' in anki_fields:
            duplicate_notes = anki_client.find_duplicate_notes(deck_name, model_name, anki_fields)
            if duplicate_notes:
                duplicate_count += 1
                continue
        
        # æ„å»ºå¡ç‰‡æ•°æ®
        note = {
            "deckName": deck_name,
            "modelName": model_name,
            "fields": anki_fields,
            "tags": DEFAULT_TAGS + ["concepts"]
        }
        
        notes_to_add.append(note)
    
    if skipped_count > 0:
        print(f"è·³è¿‡ {skipped_count} æ¡è®°å½•ï¼ˆç¼ºå°‘å¿…å¡«å­—æ®µï¼‰")
    if duplicate_count > 0:
        print(f"è·³è¿‡ {duplicate_count} æ¡è®°å½•ï¼ˆå·²å­˜åœ¨çš„é‡å¤å¡ç‰‡ï¼‰")
    
    if not notes_to_add:
        print("æ²¡æœ‰æœ‰æ•ˆçš„è®°å½•éœ€è¦æ·»åŠ ")
        # æ³¨æ„ï¼šåŒæ­¥æ“ä½œå»¶è¿Ÿåˆ°æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆåç»Ÿä¸€æ‰§è¡Œ
        return
    
    print(f"\nå‡†å¤‡æ·»åŠ  {len(notes_to_add)} å¼ å¡ç‰‡...")
    
    if dry_run:
        print("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šä¸ä¼šå®é™…æ·»åŠ å¡ç‰‡")
        print(f"ç¤ºä¾‹å¡ç‰‡ï¼ˆç¬¬ä¸€æ¡ï¼‰:")
        print(json.dumps(notes_to_add[0], ensure_ascii=False, indent=2))
        # æ³¨æ„ï¼šåŒæ­¥æ“ä½œå»¶è¿Ÿåˆ°æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆåç»Ÿä¸€æ‰§è¡Œ
        return
    
    # æ‰¹é‡æ·»åŠ å¡ç‰‡ï¼ˆä½¿ç”¨ä¼ å…¥çš„ batch_size å‚æ•°ï¼‰
    total_added = 0
    total_failed = 0
    
    for i in range(0, len(notes_to_add), batch_size):
        batch = notes_to_add[i:i + batch_size]
        try:
            result = anki_client.add_notes(batch)
            # result æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æˆåŠŸæ·»åŠ çš„å¡ç‰‡ ID å’Œ Noneï¼ˆå¤±è´¥çš„ï¼‰
            added_count = sum(1 for x in result if x is not None)
            failed_count = len(batch) - added_count
            total_added += added_count
            total_failed += failed_count
            if failed_count > 0:
                print(f"  æ‰¹æ¬¡ {i//batch_size + 1}: æˆåŠŸæ·»åŠ  {added_count}/{len(batch)} å¼ å¡ç‰‡ï¼ˆ{failed_count} å¼ å¯èƒ½é‡å¤ï¼‰")
            else:
                print(f"  æ‰¹æ¬¡ {i//batch_size + 1}: æˆåŠŸæ·»åŠ  {added_count}/{len(batch)} å¼ å¡ç‰‡")
        except Exception as e:
            error_msg = str(e)
            # å¦‚æœæ‰¹é‡æ·»åŠ å¤±è´¥ï¼Œæ”¹ä¸ºé€ä¸ªæ·»åŠ ï¼ˆæ— è®ºæ˜¯ä»€ä¹ˆé”™è¯¯ï¼‰
            print(f"  æ‰¹æ¬¡ {i//batch_size + 1}: æ‰¹é‡æ·»åŠ å¤±è´¥ï¼Œæ”¹ä¸ºé€ä¸ªæ·»åŠ ...")
            batch_added = 0
            batch_failed = 0
            batch_duplicate = 0
            
            for note_idx, note in enumerate(batch, 1):
                try:
                    note_id = anki_client.add_note(
                        deck_name=note['deckName'],
                        model_name=note['modelName'],
                        fields=note['fields'],
                        tags=note.get('tags', [])
                    )
                    if note_id:
                        batch_added += 1
                except Exception as note_error:
                    error_str = str(note_error).lower()
                    if 'duplicate' in error_str:
                        # é‡å¤çš„å¡ç‰‡ï¼Œè·³è¿‡
                        batch_duplicate += 1
                        batch_failed += 1
                    else:
                        # å…¶ä»–é”™è¯¯ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯
                        concept_name = note['fields'].get('Name', 'æœªçŸ¥')[:50]
                        print(f"    [{note_idx}/{len(batch)}] âš ï¸  æ·»åŠ å¡ç‰‡å¤±è´¥ ({concept_name}...): {note_error}")
                        batch_failed += 1
            
            total_added += batch_added
            total_failed += batch_failed
            
            # æ‰“å°æ±‡æ€»ä¿¡æ¯
            if batch_added > 0 or batch_failed > 0:
                status_parts = []
                if batch_added > 0:
                    status_parts.append(f"æˆåŠŸ {batch_added}")
                if batch_duplicate > 0:
                    status_parts.append(f"é‡å¤ {batch_duplicate}")
                if batch_failed > batch_duplicate:
                    status_parts.append(f"å¤±è´¥ {batch_failed - batch_duplicate}")
                status_str = "ï¼Œ".join(status_parts)
                print(f"  æ‰¹æ¬¡ {i//batch_size + 1}: é€ä¸ªæ·»åŠ å®Œæˆï¼ˆ{status_str}/{len(batch)} å¼ å¡ç‰‡ï¼‰")
            else:
                print(f"  æ‰¹æ¬¡ {i//batch_size + 1}: é€ä¸ªæ·»åŠ å®Œæˆï¼ŒæˆåŠŸ {batch_added}/{len(batch)} å¼ å¡ç‰‡")
    
    print(f"\nâœ“ å®Œæˆï¼å…±æ·»åŠ  {total_added}/{len(notes_to_add)} å¼ å¡ç‰‡åˆ° Anki")
    if total_failed > 0:
        print(f"âš ï¸  è·³è¿‡ {total_failed} å¼ å¡ç‰‡ï¼ˆå¯èƒ½æ˜¯é‡å¤å¡ç‰‡ï¼‰")
    
    # æ³¨æ„ï¼šåŒæ­¥æ“ä½œå»¶è¿Ÿåˆ°æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆåç»Ÿä¸€æ‰§è¡Œ


def find_book_id_by_title(csv_file: Path, book_title: str) -> Optional[str]:
    """
    æ ¹æ®ä¹¦ååœ¨ CSV æ–‡ä»¶ä¸­æŸ¥æ‰¾ bookId
    æ”¯æŒç²¾ç¡®åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…ï¼ˆå¦‚æœä¹¦ååŒ…å«åœ¨ CSV çš„ title å­—æ®µä¸­ï¼Œæˆ– CSV çš„ title åŒ…å«åœ¨è¾“å…¥çš„ä¹¦åä¸­ï¼‰
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        book_title: ä¹¦å
    
    Returns:
        bookIdï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    try:
        book_title_lower = book_title.strip().lower()
        exact_match = None
        partial_matches = []
        
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                title = row.get('title', '').strip()
                title_lower = title.lower()
                book_id = row.get('bookId', '').strip()
                
                # ç²¾ç¡®åŒ¹é…
                if title == book_title or title_lower == book_title_lower:
                    exact_match = book_id
                    break
                
                # éƒ¨åˆ†åŒ¹é…ï¼šè¾“å…¥çš„ä¹¦ååŒ…å«åœ¨ CSV çš„ title ä¸­ï¼Œæˆ– CSV çš„ title åŒ…å«åœ¨è¾“å…¥çš„ä¹¦åä¸­
                if book_title_lower in title_lower or title_lower in book_title_lower:
                    partial_matches.append((title, book_id))
        
        # ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…
        if exact_match:
            return exact_match
        
        # å¦‚æœæœ‰éƒ¨åˆ†åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€ç›¸å…³çš„ï¼‰
        if partial_matches:
            # ä¼˜å…ˆè¿”å›åŒ…å«è¾“å…¥ä¹¦åæœ€çŸ­çš„é‚£ä¸ªï¼ˆæ›´ç²¾ç¡®ï¼‰
            partial_matches.sort(key=lambda x: len(x[0]))
            return partial_matches[0][1]
        
        return None
    except Exception as e:
        print(f"é”™è¯¯ï¼šè¯»å– CSV æ–‡ä»¶å¤±è´¥: {e}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°† concepts CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # å¯¼å…¥æ‰€æœ‰ concepts CSV æ–‡ä»¶
  python import_concepts_to_anki.py
  
  # å¯¼å…¥æŒ‡å®šçš„ CSV æ–‡ä»¶
  python import_concepts_to_anki.py --file llm/output/concepts/3300089819_concepts.csv
  
  # æ ¹æ® bookId è¿‡æ»¤
  python import_concepts_to_anki.py --book-id 3300089819
  
  # æ ¹æ®ä¹¦åè¿‡æ»¤
  python import_concepts_to_anki.py --title "æç®€å¤®è¡Œè¯¾"
  
  # è‡ªåŠ¨ç”Ÿæˆ concepts CSV æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
  python import_concepts_to_anki.py --title "æç®€å¤®è¡Œè¯¾" --auto-generate
  
  # è‡ªåŠ¨ç”Ÿæˆå¹¶æŒ‡å®š API key
  python import_concepts_to_anki.py --title "æç®€å¤®è¡Œè¯¾" --auto-generate --api-key YOUR_API_KEY
  
  # è¯•è¿è¡Œï¼ˆä¸å®é™…æ·»åŠ å¡ç‰‡ï¼‰
  python import_concepts_to_anki.py --dry-run
  
  # æŒ‡å®š AnkiConnect åœ°å€
  python import_concepts_to_anki.py --anki-url http://127.0.0.1:8765
  
  # å¯¼å…¥åè‡ªåŠ¨åŒæ­¥åˆ° AnkiWeb
  python import_concepts_to_anki.py --sync
  
  # æŒ‡å®šæ‰¹é‡å¤§å°ï¼ˆæ¯æ‰¹30å¼ å¡ç‰‡ï¼‰
  python import_concepts_to_anki.py --batch-size 30
        """
    )
    
    parser.add_argument('--file', '--csv-file', dest='csv_file', type=str, default=None,
                       help='è¦å¯¼å…¥çš„ CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™å¯¼å…¥æ‰€æœ‰ concepts CSV æ–‡ä»¶ï¼‰')
    
    # ä¹¦ç±è¿‡æ»¤å‚æ•°ï¼ˆäº’æ–¥ï¼‰
    book_group = parser.add_mutually_exclusive_group()
    book_group.add_argument('--book-id', '--id', dest='book_id', type=str, default=None,
                           help='ä¹¦ç±IDï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªå¯¼å…¥è¯¥ä¹¦ç±çš„ CSV æ–‡ä»¶ï¼‰')
    book_group.add_argument('--title', '--book-title', '--book-name', dest='book_name', type=str, default=None,
                           help='ä¹¦ç±åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªå¯¼å…¥è¯¥ä¹¦ç±çš„ CSV æ–‡ä»¶ï¼‰')
    
    parser.add_argument('--anki-url', type=str, default=None,
                       help=f'AnkiConnect API åœ°å€ï¼ˆé»˜è®¤: {ANKI_CONNECT_URL}ï¼‰')
    parser.add_argument('--model', '--model-name', dest='model_name', type=str, default=None,
                       help=f'Anki å¡ç‰Œæ¨¡æ¿åç§°ï¼ˆé»˜è®¤: {ANKI_MODEL_NAME}ï¼‰')
    parser.add_argument('--dry-run', dest='dry_run', action='store_true',
                       help='è¯•è¿è¡Œæ¨¡å¼ï¼šä¸å®é™…æ·»åŠ å¡ç‰‡ï¼Œåªæ˜¾ç¤ºå°†è¦æ·»åŠ çš„å†…å®¹')
    parser.add_argument('--sync', dest='sync', action='store_true',
                       help='å¯¼å…¥åè‡ªåŠ¨åŒæ­¥åˆ° AnkiWebï¼ˆå·²å¼ƒç”¨ï¼šç°åœ¨æ€»æ˜¯ä¼šè‡ªåŠ¨åŒæ­¥ï¼‰')
    parser.add_argument('--auto-generate', dest='auto_generate', action='store_true',
                       help='å¦‚æœæ‰¾ä¸åˆ° concepts CSV æ–‡ä»¶ï¼Œè‡ªåŠ¨è°ƒç”¨ extract_concepts.py ç”Ÿæˆ')
    parser.add_argument('--fetch', '--refresh-data', dest='fetch_data', action='store_true',
                       help='åœ¨ç”Ÿæˆ concepts ä¹‹å‰ï¼Œå…ˆé‡æ–° fetch ç¬”è®°æ•°æ®ï¼ˆè°ƒç”¨ wereader/fetch.pyï¼‰')
    parser.add_argument('--api-key', dest='api_key', type=str, default=None,
                       help='Gemini API å¯†é’¥ï¼ˆç”¨äºè‡ªåŠ¨ç”Ÿæˆ conceptsï¼Œä¼˜å…ˆä»ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEY è¯»å–ï¼‰')
    parser.add_argument('--batch-size', dest='batch_size', type=int, default=100,
                       help='æ‰¹é‡æ·»åŠ å¡ç‰‡çš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 100ï¼Œå»ºè®®èŒƒå›´: 10-200ï¼‰')
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = Path(__file__).parent  # anki/scripts
    project_root = script_dir.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
    
    # é»˜è®¤è·¯å¾„
    concepts_dir = project_root / "llm" / "output" / "concepts"
    books_csv = project_root / "wereader" / "output" / "fetch_notebooks_output.csv"
    
    # åˆ›å»º AnkiConnect å®¢æˆ·ç«¯
    try:
        anki_client = AnkiConnectClient(url=args.anki_url)
        print("âœ“ æˆåŠŸè¿æ¥åˆ° AnkiConnect")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è¿æ¥åˆ° AnkiConnect: {e}")
        return
    
    # ç¡®å®šè¦å¤„ç†çš„ CSV æ–‡ä»¶åˆ—è¡¨
    csv_files = []
    
    if args.csv_file:
        # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶è·¯å¾„ï¼Œåªå¤„ç†è¯¥æ–‡ä»¶
        csv_file = Path(args.csv_file)
        if not csv_file.is_absolute():
            csv_file = project_root / csv_file
        if csv_file.exists():
            csv_files.append(csv_file)
        else:
            print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
    else:
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ–‡ä»¶ï¼Œå¤„ç†æ‰€æœ‰ concepts CSV æ–‡ä»¶
        if not concepts_dir.exists():
            print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨: {concepts_dir}")
            return
        
        # è·å–æ‰€æœ‰ CSV æ–‡ä»¶
        all_csv_files = list(concepts_dir.glob("*.csv"))
        
        if args.book_id:
            # æ ¹æ® bookId è¿‡æ»¤
            target_file = concepts_dir / f"{args.book_id}_concepts.csv"
            # å¦‚æœæŒ‡å®šäº† --fetchï¼Œå³ä½¿æ‰¾åˆ°äº†æ–‡ä»¶ï¼Œä¹Ÿè¦å…ˆ fetch å¹¶é‡æ–°ç”Ÿæˆ
            if args.fetch_data and args.auto_generate:
                print(f"\nğŸ”„ æ£€æµ‹åˆ° --fetch å‚æ•°ï¼Œå°†å…ˆé‡æ–° fetch æ•°æ®å¹¶ç”Ÿæˆ concepts...")
                if generate_concepts is None:
                    print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ extract_concepts æ¨¡å—ï¼Œæ— æ³•é‡æ–°ç”Ÿæˆ concepts")
                    print(f"å¯èƒ½çš„åŸå› ï¼š")
                    print(f"  1. ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼ˆå¦‚ google-generativeaiï¼‰")
                    print(f"     è¯·è¿è¡Œ: pip install google-generativeai")
                    print(f"  2. Python è·¯å¾„é…ç½®é—®é¢˜")
                    print(f"\nè¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°ç”Ÿæˆ conceptsï¼š")
                    print(f"  python llm/scripts/extract_concepts.py --book-name \"{args.book_name or 'BOOK_NAME'}\" --fetch")
                    return
                
                print(f"\nğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆ concepts CSV æ–‡ä»¶ï¼ˆä½¿ç”¨æœ€æ–°æ•°æ®ï¼‰...")
                try:
                    api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                    if not api_key:
                        print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                        print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                        return
                    
                    generate_concepts(book_id=args.book_id, api_key=api_key, fetch_data=True)
                    
                    # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                    if target_file.exists():
                        csv_files.append(target_file)
                        print(f"âœ“ æˆåŠŸé‡æ–°ç”Ÿæˆ concepts CSV æ–‡ä»¶")
                    else:
                        print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                        return
                except Exception as e:
                    print(f"âŒ é‡æ–°ç”Ÿæˆ concepts å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return
            elif target_file.exists():
                csv_files.append(target_file)
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ° bookId '{args.book_id}' å¯¹åº”çš„ concepts CSV æ–‡ä»¶")
                # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ç”Ÿæˆï¼Œå°è¯•ç”Ÿæˆ
                if args.auto_generate:
                    if generate_concepts is None:
                        print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ extract_concepts æ¨¡å—ï¼Œæ— æ³•è‡ªåŠ¨ç”Ÿæˆ concepts")
                        print(f"å¯èƒ½çš„åŸå› ï¼š")
                        print(f"  1. ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼ˆå¦‚ google-generativeaiï¼‰")
                        print(f"     è¯·è¿è¡Œ: pip install google-generativeai")
                        print(f"  2. Python è·¯å¾„é…ç½®é—®é¢˜")
                        print(f"\nè¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆ conceptsï¼š")
                        print(f"  python llm/scripts/extract_concepts.py --book-id {args.book_id}")
                        return
                    
                    print(f"\nğŸ”„ æ­£åœ¨è‡ªåŠ¨ç”Ÿæˆ concepts CSV æ–‡ä»¶...")
                    try:
                        api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                        if not api_key:
                            print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                            print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                            return
                        
                        generate_concepts(book_id=args.book_id, api_key=api_key, fetch_data=args.fetch_data)
                        
                        # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                        if target_file.exists():
                            csv_files.append(target_file)
                            print(f"âœ“ æˆåŠŸç”Ÿæˆ concepts CSV æ–‡ä»¶")
                        else:
                            print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                            return
                    except Exception as e:
                        print(f"âŒ è‡ªåŠ¨ç”Ÿæˆ concepts å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        return
                else:
                    print(f"\næç¤ºï¼šå¯ä»¥ä½¿ç”¨ --auto-generate å‚æ•°è‡ªåŠ¨ç”Ÿæˆï¼š")
                    print(f"  python anki/scripts/import_concepts_to_anki.py --book-id {args.book_id} --auto-generate")
                    return
        elif args.book_name:
            # æ ¹æ®ä¹¦åè¿‡æ»¤
            if not books_csv.exists():
                print(f"âŒ é”™è¯¯ï¼šæ— æ³•æŸ¥æ‰¾ä¹¦åå¯¹åº”çš„ bookIdï¼Œä¹¦ç±åˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {books_csv}")
                return
            
            book_id = find_book_id_by_title(books_csv, args.book_name)
            if book_id:
                target_file = concepts_dir / f"{book_id}_concepts.csv"
                # å¦‚æœæŒ‡å®šäº† --fetchï¼Œå³ä½¿æ‰¾åˆ°äº†æ–‡ä»¶ï¼Œä¹Ÿè¦å…ˆ fetch å¹¶é‡æ–°ç”Ÿæˆ
                if args.fetch_data and args.auto_generate:
                    print(f"\nğŸ”„ æ£€æµ‹åˆ° --fetch å‚æ•°ï¼Œå°†å…ˆé‡æ–° fetch æ•°æ®å¹¶ç”Ÿæˆ concepts...")
                    if generate_concepts is None:
                        print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ extract_concepts æ¨¡å—ï¼Œæ— æ³•é‡æ–°ç”Ÿæˆ concepts")
                        print(f"å¯èƒ½çš„åŸå› ï¼š")
                        print(f"  1. ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼ˆå¦‚ google-generativeaiï¼‰")
                        print(f"     è¯·è¿è¡Œ: pip install google-generativeai")
                        print(f"  2. Python è·¯å¾„é…ç½®é—®é¢˜")
                        print(f"\nè¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°ç”Ÿæˆ conceptsï¼š")
                        print(f"  python llm/scripts/extract_concepts.py --book-name \"{args.book_name}\" --fetch")
                        return
                    
                    print(f"\nğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆ concepts CSV æ–‡ä»¶ï¼ˆä½¿ç”¨æœ€æ–°æ•°æ®ï¼‰...")
                    try:
                        api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                        if not api_key:
                            print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                            print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                            return
                        
                        # ç›´æ¥ä½¿ç”¨å·²æ‰¾åˆ°çš„ bookIdï¼Œé¿å…é‡å¤æŸ¥æ‰¾
                        generate_concepts(book_id=book_id, api_key=api_key, fetch_data=True)
                        
                        # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                        if target_file.exists():
                            csv_files.append(target_file)
                            print(f"âœ“ æˆåŠŸé‡æ–°ç”Ÿæˆ concepts CSV æ–‡ä»¶")
                        else:
                            print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                            return
                    except Exception as e:
                        print(f"âŒ é‡æ–°ç”Ÿæˆ concepts å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        return
                elif target_file.exists():
                    csv_files.append(target_file)
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°ä¹¦å '{args.book_name}' å¯¹åº”çš„ concepts CSV æ–‡ä»¶")
                    # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ç”Ÿæˆï¼Œå°è¯•ç”Ÿæˆ
                    if args.auto_generate:
                        if generate_concepts is None:
                            print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ extract_concepts æ¨¡å—ï¼Œæ— æ³•è‡ªåŠ¨ç”Ÿæˆ concepts")
                            print(f"å¯èƒ½çš„åŸå› ï¼š")
                            print(f"  1. ç¼ºå°‘ä¾èµ–æ¨¡å—ï¼ˆå¦‚ google-generativeaiï¼‰")
                            print(f"     è¯·è¿è¡Œ: pip install google-generativeai")
                            print(f"  2. Python è·¯å¾„é…ç½®é—®é¢˜")
                            print(f"\nè¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆ conceptsï¼š")
                            print(f"  python llm/scripts/extract_concepts.py --book-name \"{args.book_name}\"")
                            return
                        
                        print(f"\nğŸ”„ æ­£åœ¨è‡ªåŠ¨ç”Ÿæˆ concepts CSV æ–‡ä»¶...")
                        try:
                            api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                            if not api_key:
                                print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                                print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                                return
                            
                            # ç›´æ¥ä½¿ç”¨å·²æ‰¾åˆ°çš„ bookIdï¼Œé¿å…é‡å¤æŸ¥æ‰¾
                            generate_concepts(book_id=book_id, api_key=api_key, fetch_data=args.fetch_data)
                            
                            # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                            if target_file.exists():
                                csv_files.append(target_file)
                                print(f"âœ“ æˆåŠŸç”Ÿæˆ concepts CSV æ–‡ä»¶")
                            else:
                                print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                                return
                        except Exception as e:
                            print(f"âŒ è‡ªåŠ¨ç”Ÿæˆ concepts å¤±è´¥: {e}")
                            import traceback
                            traceback.print_exc()
                            return
                    else:
                        print(f"\næç¤ºï¼šå¯ä»¥ä½¿ç”¨ --auto-generate å‚æ•°è‡ªåŠ¨ç”Ÿæˆï¼š")
                        print(f"  python anki/scripts/import_concepts_to_anki.py --title \"{args.book_name}\" --auto-generate")
                        return
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°ä¹¦å '{args.book_name}' å¯¹åº”çš„ bookId")
                return
        else:
            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            csv_files = all_csv_files
    
    if not csv_files:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„ CSV æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶éœ€è¦å¤„ç†")
    
    # å¤„ç†æ¯ä¸ª CSV æ–‡ä»¶
    for csv_file in csv_files:
        try:
            import_csv_to_anki(
                csv_file=csv_file,
                anki_client=anki_client,
                model_name=args.model_name,
                dry_run=args.dry_run,
                sync=args.sync,
                batch_size=args.batch_size
            )
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {csv_file.name} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"\n{'='*60}")
    print("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")
    print(f"{'='*60}")
    
    # æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆåï¼Œå¼ºåˆ¶åŒæ­¥åˆ° AnkiWeb
    print(f"\næ­£åœ¨åŒæ­¥åˆ° AnkiWeb...")
    if anki_client.sync():
        print(f"âœ“ åŒæ­¥æˆåŠŸ")
    else:
        print(f"âš ï¸  åŒæ­¥å¤±è´¥ï¼Œè¯·ç¨åæ‰‹åŠ¨åŒæ­¥")


if __name__ == "__main__":
    main()

