#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°† marknotes CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki
ä½¿ç”¨ AnkiConnect API å°† MarkNotes å¡ç‰‡æ·»åŠ åˆ° Anki
"""

import json
import csv
import os
import sys
import requests
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from config import (
    ANKI_CONNECT_URL,
    ANKI_MODEL_NAME,
    DECK_NAME_PREFIX,
    DEFAULT_TAGS
)

# å¯¼å…¥ generate_marknotes æ¨¡å—
try:
    # ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œæ—¶
    script_dir = Path(__file__).parent  # anki/scripts
    project_root = script_dir.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
    sys.path.insert(0, str(project_root))
    from llm.scripts.generate_marknotes import process_csv_file as generate_marknotes
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥å¯¼å…¥
    try:
        sys.path.insert(0, str(Path(__file__).parent.parent.parent / "llm" / "scripts"))
        from generate_marknotes import process_csv_file as generate_marknotes
    except ImportError:
        generate_marknotes = None

# MarkNotes å¡ç‰Œç»„å‘½åæ ¼å¼
# æ ¼å¼ï¼š{prefix}::{category}::{book_title}
# ä¾‹å¦‚ï¼šå¾®ä¿¡è¯»ä¹¦::marknotes::æç®€å¤®è¡Œè¯¾
MARKNOTES_DECK_NAME_CATEGORY = "marknotes"
MARKNOTES_DECK_NAME_FORMAT = f"{DECK_NAME_PREFIX}::{MARKNOTES_DECK_NAME_CATEGORY}::{{book_title}}"

# MarkNotes CSV åˆ—å -> Anki å­—æ®µå çš„æ˜ å°„
MARKNOTES_FIELD_MAPPING = {
    'reviewContentHTML': 'AINotes',  # HTML å†…å®¹ -> AINotes
    'title': 'Source',                # ä¹¦å -> Source
    'categories': 'Field',            # åˆ†ç±» -> Field
    'markText': 'References'          # åŸæ–‡ -> References
    # Name å­—æ®µéœ€è¦ç‰¹æ®Šå¤„ç†ï¼šä¹¦å-chapterName-reviewId
}


class AnkiConnectClient:
    """AnkiConnect API å®¢æˆ·ç«¯"""
    
    def __init__(self, url: Optional[str] = None):
        """
        åˆå§‹åŒ– AnkiConnect å®¢æˆ·ç«¯
        
        Args:
            url: AnkiConnect API åœ°å€ï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ï¼‰
        """
        self.url = url or ANKI_CONNECT_URL
    
    def _invoke(self, action: str, **params) -> Dict:
        """
        è°ƒç”¨ AnkiConnect API
        
        Args:
            action: API åŠ¨ä½œåç§°
            **params: API å‚æ•°
        
        Returns:
            API å“åº”ç»“æœ
        """
        payload = {
            "action": action,
            "version": 6,
            "params": params
        }
        
        try:
            response = requests.post(self.url, json=payload, timeout=10)
            response.raise_for_status()
            result = response.json()
            
            if len(result) != 2:
                raise Exception(f"å“åº”æ ¼å¼é”™è¯¯: {result}")
            
            if result.get("error") is not None:
                raise Exception(f"AnkiConnect é”™è¯¯: {result['error']}")
            
            return result.get("result")
        
        except requests.exceptions.ConnectionError:
            raise Exception("æ— æ³•è¿æ¥åˆ° AnkiConnectã€‚è¯·ç¡®ä¿ Anki æ­£åœ¨è¿è¡Œï¼Œå¹¶ä¸”å·²å®‰è£… AnkiConnect æ’ä»¶ã€‚")
        except requests.exceptions.Timeout:
            raise Exception("AnkiConnect è¯·æ±‚è¶…æ—¶")
        except Exception as e:
            raise Exception(f"è°ƒç”¨ AnkiConnect API å¤±è´¥: {e}")
    
    def get_model_field_names(self, model_name: str) -> List[str]:
        """
        è·å–å¡ç‰Œæ¨¡æ¿çš„å­—æ®µååˆ—è¡¨
        
        Args:
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
        
        Returns:
            å­—æ®µååˆ—è¡¨
        """
        return self._invoke("modelFieldNames", modelName=model_name)
    
    def deck_exists(self, deck_name: str) -> bool:
        """
        æ£€æŸ¥å¡ç‰Œç»„æ˜¯å¦å­˜åœ¨
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
        
        Returns:
            å¦‚æœå­˜åœ¨è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        deck_names = self._invoke("deckNames")
        return deck_name in deck_names
    
    def ensure_deck_exists(self, deck_name: str) -> bool:
        """
        ç¡®ä¿å¡ç‰Œç»„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
        
        Returns:
            å¦‚æœæˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            self._invoke("createDeck", deck=deck_name)
            return True
        except Exception as e:
            error_msg = str(e).lower()
            if "already exists" in error_msg or "å·²å­˜åœ¨" in error_msg:
                return True
            return False
    
    def find_duplicate_notes(self, deck_name: str, model_name: str, fields: Dict[str, str]) -> List[int]:
        """
        æŸ¥æ‰¾é‡å¤çš„å¡ç‰‡ï¼ˆåŸºäº Name å­—æ®µï¼‰
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
            fields: å¡ç‰‡å­—æ®µå­—å…¸
        
        Returns:
            é‡å¤å¡ç‰‡çš„ note ID åˆ—è¡¨
        """
        if 'Name' not in fields:
            return []
        
        # ä½¿ç”¨ Name å­—æ®µè¿›è¡Œç²¾ç¡®åŒ¹é…
        name_value = fields['Name']
        if not name_value or not name_value.strip():
            return []
        
        # è½¬ä¹‰ç‰¹æ®Šå­—ç¬¦
        escaped_name = name_value.replace('"', '\\"')
        query = f'deck:"{deck_name}" note:"{model_name}" "Name:{escaped_name}"'
        
        try:
            note_ids = self._invoke("findNotes", query=query)
            return note_ids if note_ids else []
        except Exception as e:
            # å¦‚æœæŸ¥è¯¢å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            return []
    
    def add_note(self, deck_name: str, model_name: str, fields: Dict[str, str], tags: List[str] = None) -> Optional[int]:
        """
        æ·»åŠ ä¸€å¼ å¡ç‰‡
        
        Args:
            deck_name: å¡ç‰Œç»„åç§°
            model_name: å¡ç‰Œæ¨¡æ¿åç§°
            fields: å¡ç‰‡å­—æ®µå­—å…¸
            tags: æ ‡ç­¾åˆ—è¡¨
        
        Returns:
            æ–°åˆ›å»ºçš„å¡ç‰‡ IDï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        note = {
            "deckName": deck_name,
            "modelName": model_name,
            "fields": fields,
            "tags": tags or []
        }
        
        try:
            note_id = self._invoke("addNote", note=note)
            return note_id
        except Exception as e:
            error_msg = str(e).lower()
            if "duplicate" in error_msg or "é‡å¤" in error_msg:
                # å¦‚æœæ˜¯é‡å¤å¡ç‰‡ï¼Œè¿”å› None
                return None
            raise
    
    def add_notes(self, notes: List[Dict]) -> List[Optional[int]]:
        """
        æ‰¹é‡æ·»åŠ å¡ç‰‡
        
        Args:
            notes: å¡ç‰‡åˆ—è¡¨ï¼Œæ¯ä¸ªå¡ç‰‡æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« deckName, modelName, fields, tags
        
        Returns:
            æ–°åˆ›å»ºçš„å¡ç‰‡ ID åˆ—è¡¨ï¼Œå¦‚æœå¤±è´¥åˆ™å¯¹åº”ä½ç½®ä¸º None
        """
        try:
            note_ids = self._invoke("addNotes", notes=notes)
            return note_ids
        except Exception as e:
            raise Exception(f"æ‰¹é‡æ·»åŠ å¡ç‰‡å¤±è´¥: {e}")
    
    def update_note_fields(self, note_id: int, fields: Dict[str, str]) -> bool:
        """
        æ›´æ–°å¡ç‰‡çš„å­—æ®µ
        
        Args:
            note_id: å¡ç‰‡ ID
            fields: è¦æ›´æ–°çš„å­—æ®µå­—å…¸
        
        Returns:
            å¦‚æœæˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            self._invoke("updateNoteFields", note={"id": note_id, "fields": fields})
            return True
        except Exception as e:
            return False
    
    def sync(self) -> bool:
        """
        åŒæ­¥ Anki åˆ° AnkiWeb
        
        Returns:
            å¦‚æœæˆåŠŸè¿”å› Trueï¼Œå¦åˆ™è¿”å› False
        """
        try:
            # AnkiConnect çš„ sync API ä¼šè§¦å‘åŒæ­¥ï¼ŒæˆåŠŸæ—¶é€šå¸¸è¿”å› None
            # æ³¨æ„ï¼šsync æ˜¯å¼‚æ­¥æ“ä½œï¼Œå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´
            result = self._invoke("sync")
            # sync æ“ä½œæˆåŠŸæ—¶é€šå¸¸è¿”å› None æˆ–ç©ºå€¼
            # å³ä½¿è¿”å› None ä¹Ÿè®¤ä¸ºæ˜¯æˆåŠŸï¼ˆå› ä¸º sync æ˜¯å¼‚æ­¥çš„ï¼‰
            return True
        except Exception as e:
            error_msg = str(e).lower()
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸¸è§çš„åŒæ­¥é”™è¯¯
            if "authentication" in error_msg.lower() or "login" in error_msg.lower() or "not logged in" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: è¯·å…ˆåœ¨ Anki ä¸­ç™»å½• AnkiWeb è´¦å·")
                print(f"     æ“ä½œæ­¥éª¤ï¼šAnki -> æ–‡ä»¶ -> åŒæ­¥ -> ç™»å½• AnkiWeb")
            elif "already syncing" in error_msg.lower() or "sync in progress" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: Anki æ­£åœ¨åŒæ­¥ä¸­ï¼Œè¯·ç¨åå†è¯•")
            elif "network" in error_msg.lower() or "connection" in error_msg.lower():
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
            else:
                print(f"  âš ï¸  åŒæ­¥å¤±è´¥: {error_msg}")
                print(f"     æç¤ºï¼šè¯·ç¡®ä¿å·²åœ¨ Anki ä¸­ç™»å½• AnkiWeb è´¦å·ï¼Œå¹¶ä¸”ç½‘ç»œè¿æ¥æ­£å¸¸")
            return False


def read_csv_file(csv_file: Path) -> List[Dict[str, str]]:
    """è¯»å– CSV æ–‡ä»¶"""
    rows = []
    if not csv_file.exists():
        print(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
        return rows
    
    try:
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                rows.append(row)
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return rows


def get_book_title_from_csv(csv_file: Path) -> Optional[str]:
    """
    ä» CSV æ–‡ä»¶ä¸­è·å–ä¹¦åï¼ˆä»ç¬¬ä¸€è¡Œï¼‰
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
    
    Returns:
        ä¹¦åï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    rows = read_csv_file(csv_file)
    if rows:
        return rows[0].get('title', '').strip()
    return None


def map_csv_fields_to_anki_fields(csv_row: Dict[str, str], field_mapping: Dict[str, str]) -> Dict[str, str]:
    """
    å°† CSV è¡Œæ•°æ®æ˜ å°„åˆ° Anki å­—æ®µ
    
    Args:
        csv_row: CSV è¡Œæ•°æ®å­—å…¸
        field_mapping: å­—æ®µæ˜ å°„å…³ç³»
    
    Returns:
        Anki å­—æ®µå­—å…¸
    """
    anki_fields = {}
    
    # ç‰¹æ®Šå¤„ç† Name å­—æ®µï¼šä¹¦å-chapterName-reviewId
    book_title = csv_row.get('title', '').strip()
    chapter_name = csv_row.get('chapterName', '').strip()
    review_id = csv_row.get('reviewId', '').strip()
    
    # æ„å»º Name å­—æ®µ
    name_parts = []
    if book_title:
        name_parts.append(book_title)
    if chapter_name:
        name_parts.append(chapter_name)
    if review_id:
        name_parts.append(review_id)
    
    anki_fields['Name'] = '-'.join(name_parts) if name_parts else ''
    
    # æ˜ å°„å…¶ä»–å­—æ®µ
    for csv_field, anki_field in field_mapping.items():
        value = csv_row.get(csv_field, '').strip()
        anki_fields[anki_field] = value
    
    return anki_fields


def import_csv_to_anki(csv_file: Path, anki_client: AnkiConnectClient, model_name: Optional[str] = None, 
                       field_mapping: Optional[Dict[str, str]] = None, dry_run: bool = False, sync: bool = False,
                       batch_size: int = 100):
    """
    å°† CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        anki_client: AnkiConnect å®¢æˆ·ç«¯
        model_name: Anki å¡ç‰Œæ¨¡æ¿åç§°ï¼ˆé»˜è®¤: KWDictï¼‰
        field_mapping: å­—æ®µæ˜ å°„å…³ç³»ï¼ˆå¦‚æœä¸º Noneï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„ï¼‰
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œï¼ˆä¸å®é™…æ·»åŠ å¡ç‰‡ï¼‰
        sync: æ˜¯å¦åŒæ­¥åˆ° AnkiWebï¼ˆå·²å¼ƒç”¨ï¼Œç°åœ¨æ€»æ˜¯ä¼šè‡ªåŠ¨åŒæ­¥ï¼‰
        batch_size: æ‰¹é‡æ·»åŠ å¡ç‰‡çš„æ‰¹æ¬¡å¤§å°
    """
    if field_mapping is None:
        field_mapping = MARKNOTES_FIELD_MAPPING
    
    if model_name is None:
        model_name = ANKI_MODEL_NAME
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ–‡ä»¶: {csv_file.name}")
    print(f"{'='*60}")
    
    # è¯»å– CSV æ–‡ä»¶
    rows = read_csv_file(csv_file)
    if not rows:
        print(f"âš ï¸  æ–‡ä»¶ä¸ºç©ºæˆ–è¯»å–å¤±è´¥ï¼Œè·³è¿‡")
        return
    
    print(f"è¯»å–åˆ° {len(rows)} æ¡è®°å½•")
    
    # è·å–ä¹¦åï¼ˆä»ç¬¬ä¸€è¡Œï¼‰
    book_title = get_book_title_from_csv(csv_file)
    if not book_title:
        print(f"âš ï¸  æ— æ³•è·å–ä¹¦åï¼Œè·³è¿‡")
        return
    
    # æ„å»ºå¡ç‰Œç»„åç§°ï¼ˆä½¿ç”¨é…ç½®ä¸­çš„æ ¼å¼ï¼‰
    deck_name = MARKNOTES_DECK_NAME_FORMAT.format(book_title=book_title)
    print(f"å¡ç‰Œç»„: {deck_name}")
    print(f"å¡ç‰Œæ¨¡æ¿: {model_name}")
    
    # ç¡®ä¿å¡ç‰Œç»„å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
    if not anki_client.deck_exists(deck_name):
        print(f"å¡ç‰Œç»„ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
        if anki_client.ensure_deck_exists(deck_name):
            print(f"âœ“ æˆåŠŸåˆ›å»ºå¡ç‰Œç»„: {deck_name}")
        else:
            print(f"âŒ é”™è¯¯ï¼šæ— æ³•åˆ›å»ºå¡ç‰Œç»„: {deck_name}")
            return
    else:
        print(f"âœ“ å¡ç‰Œç»„å·²å­˜åœ¨: {deck_name}")
    
    # éªŒè¯å¡ç‰Œæ¨¡æ¿æ˜¯å¦å­˜åœ¨
    try:
        field_names = anki_client.get_model_field_names(model_name)
        print(f"å¡ç‰Œæ¨¡æ¿å­—æ®µ: {', '.join(field_names)}")
    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼šæ— æ³•è·å–å¡ç‰Œæ¨¡æ¿ '{model_name}' çš„ä¿¡æ¯: {e}")
        return
    
    # éªŒè¯æ˜ å°„çš„å­—æ®µæ˜¯å¦å­˜åœ¨äºå¡ç‰Œæ¨¡æ¿ä¸­
    mapped_fields = set(field_mapping.values())
    mapped_fields.add('Name')  # Name å­—æ®µæ˜¯ç‰¹æ®Šå¤„ç†çš„
    missing_fields = mapped_fields - set(field_names)
    if missing_fields:
        print(f"âš ï¸  è­¦å‘Šï¼šä»¥ä¸‹æ˜ å°„çš„å­—æ®µåœ¨å¡ç‰Œæ¨¡æ¿ä¸­ä¸å­˜åœ¨: {', '.join(missing_fields)}")
    
    # å‡†å¤‡è¦æ·»åŠ çš„å¡ç‰‡
    notes_to_add = []
    skipped_count = 0
    duplicate_count = 0
    
    print(f"\næ£€æŸ¥é‡å¤å¡ç‰‡...")
    for i, row in enumerate(rows, 1):
        # æ˜ å°„å­—æ®µ
        anki_fields = map_csv_fields_to_anki_fields(row, field_mapping)
        
        # æ£€æŸ¥å¿…å¡«å­—æ®µï¼ˆName å­—æ®µå’Œ AINotes å­—æ®µï¼‰
        if not anki_fields.get('Name', '').strip():
            skipped_count += 1
            continue
        
        if not anki_fields.get('AINotes', '').strip():
            skipped_count += 1
            continue
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é‡å¤å¡ç‰‡ï¼ˆåŸºäº Name å­—æ®µï¼‰
        duplicate_notes = anki_client.find_duplicate_notes(deck_name, model_name, anki_fields)
        if duplicate_notes:
            duplicate_count += 1
            continue
        
        # æ„å»ºå¡ç‰‡æ•°æ®
        note = {
            "deckName": deck_name,
            "modelName": model_name,
            "fields": anki_fields,
            "tags": DEFAULT_TAGS + ["marknotes"]
        }
        
        notes_to_add.append(note)
    
    if skipped_count > 0:
        print(f"è·³è¿‡ {skipped_count} æ¡è®°å½•ï¼ˆç¼ºå°‘å¿…å¡«å­—æ®µï¼‰")
    if duplicate_count > 0:
        print(f"è·³è¿‡ {duplicate_count} æ¡è®°å½•ï¼ˆå·²å­˜åœ¨çš„é‡å¤å¡ç‰‡ï¼‰")
    
    if not notes_to_add:
        print("æ²¡æœ‰æœ‰æ•ˆçš„è®°å½•éœ€è¦æ·»åŠ ")
        return
    
    print(f"\nå‡†å¤‡æ·»åŠ  {len(notes_to_add)} å¼ å¡ç‰‡...")
    
    if dry_run:
        print("ğŸ” è¯•è¿è¡Œæ¨¡å¼ï¼šä¸ä¼šå®é™…æ·»åŠ å¡ç‰‡")
        for i, note in enumerate(notes_to_add[:3], 1):  # åªæ˜¾ç¤ºå‰3å¼ 
            print(f"\nå¡ç‰‡ {i}:")
            print(json.dumps({
                "deckName": note['deckName'],
                "modelName": note['modelName'],
                "fields": {k: v[:100] + '...' if len(v) > 100 else v for k, v in note['fields'].items()},
                "tags": note['tags']
            }, ensure_ascii=False, indent=2))
        if len(notes_to_add) > 3:
            print(f"\n... è¿˜æœ‰ {len(notes_to_add) - 3} å¼ å¡ç‰‡")
        return
    
    # æ‰¹é‡æ·»åŠ å¡ç‰‡
    added_count = 0
    failed_count = 0
    duplicate_count_final = 0
    
    for i in range(0, len(notes_to_add), batch_size):
        batch = notes_to_add[i:i + batch_size]
        batch_num = i // batch_size + 1
        
        try:
            note_ids = anki_client.add_notes(batch)
            # ç»Ÿè®¡æˆåŠŸæ·»åŠ çš„æ•°é‡ï¼ˆé None çš„ IDï¼‰
            success_in_batch = sum(1 for note_id in note_ids if note_id is not None)
            added_count += success_in_batch
            failed_in_batch = len(batch) - success_in_batch
            if failed_in_batch > 0:
                print(f"  æ‰¹æ¬¡ {batch_num}: æ‰¹é‡æ·»åŠ éƒ¨åˆ†å¤±è´¥ï¼Œæ”¹ä¸ºé€ä¸ªæ·»åŠ ...")
                # é€ä¸ªæ·»åŠ å¤±è´¥çš„å¡ç‰‡
                for note in batch:
                    try:
                        note_id = anki_client.add_note(
                            deck_name=note['deckName'],
                            model_name=note['modelName'],
                            fields=note['fields'],
                            tags=note.get('tags', [])
                        )
                        if note_id:
                            added_count += 1
                        else:
                            failed_count += 1
                    except Exception as e:
                        error_msg = str(e)
                        if 'duplicate' in error_msg.lower():
                            duplicate_count_final += 1
                        else:
                            failed_count += 1
        except Exception as e:
            error_msg = str(e)
            print(f"  æ‰¹æ¬¡ {batch_num}: æ‰¹é‡æ·»åŠ å¤±è´¥ï¼Œæ”¹ä¸ºé€ä¸ªæ·»åŠ ...")
            # æ‰¹é‡å¤±è´¥ï¼Œæ”¹ä¸ºé€ä¸ªæ·»åŠ 
            for note in batch:
                try:
                    note_id = anki_client.add_note(
                        deck_name=note['deckName'],
                        model_name=note['modelName'],
                        fields=note['fields'],
                        tags=note.get('tags', [])
                    )
                    if note_id:
                        added_count += 1
                    else:
                        failed_count += 1
                except Exception as e2:
                    error_msg2 = str(e2)
                    if 'duplicate' in error_msg2.lower():
                        duplicate_count_final += 1
                    else:
                        failed_count += 1
    
    print(f"\nâœ“ å®Œæˆï¼å…±æ·»åŠ  {added_count}/{len(notes_to_add)} å¼ å¡ç‰‡åˆ° Anki")
    if duplicate_count_final > 0:
        print(f"âš ï¸  è·³è¿‡ {duplicate_count_final} å¼ å¡ç‰‡ï¼ˆå¯èƒ½æ˜¯é‡å¤å¡ç‰‡ï¼‰")
    if failed_count > 0:
        print(f"âŒ å¤±è´¥ {failed_count} å¼ å¡ç‰‡")


def find_book_id_by_title(csv_file: Path, book_title: str) -> Optional[str]:
    """
    æ ¹æ®ä¹¦ååœ¨ CSV æ–‡ä»¶ä¸­æŸ¥æ‰¾ bookId
    æ”¯æŒç²¾ç¡®åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…
    
    Args:
        csv_file: CSV æ–‡ä»¶è·¯å¾„
        book_title: ä¹¦å
    
    Returns:
        bookIdï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å› None
    """
    try:
        book_title_lower = book_title.strip().lower()
        exact_match = None
        partial_matches = []
        
        with open(csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                title = row.get('title', '').strip()
                title_lower = title.lower()
                book_id = row.get('bookId', '').strip()
                
                # ç²¾ç¡®åŒ¹é…
                if title == book_title or title_lower == book_title_lower:
                    exact_match = book_id
                    break
                
                # éƒ¨åˆ†åŒ¹é…ï¼šè¾“å…¥çš„ä¹¦ååŒ…å«åœ¨ CSV çš„ title ä¸­ï¼Œæˆ– CSV çš„ title åŒ…å«åœ¨è¾“å…¥çš„ä¹¦åä¸­
                if book_title_lower in title_lower or title_lower in book_title_lower:
                    partial_matches.append((title, book_id))
        
        # ä¼˜å…ˆè¿”å›ç²¾ç¡®åŒ¹é…
        if exact_match:
            return exact_match
        
        # å¦‚æœæœ‰éƒ¨åˆ†åŒ¹é…ï¼Œè¿”å›ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€ç›¸å…³çš„ï¼‰
        if partial_matches:
            # ä¼˜å…ˆè¿”å›åŒ…å«è¾“å…¥ä¹¦åæœ€çŸ­çš„é‚£ä¸ªï¼ˆæ›´ç²¾ç¡®ï¼‰
            partial_matches.sort(key=lambda x: len(x[0]))
            return partial_matches[0][1]
        
        return None
    except Exception as e:
        print(f"é”™è¯¯ï¼šè¯»å– CSV æ–‡ä»¶å¤±è´¥: {e}")
        return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°† marknotes CSV æ–‡ä»¶å¯¼å…¥åˆ° Anki',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # å¯¼å…¥æ‰€æœ‰ marknotes æ–‡ä»¶
  python import_marknotes_to_anki.py
  
  # å¯¼å…¥æŒ‡å®šçš„ CSV æ–‡ä»¶
  python import_marknotes_to_anki.py --file llm/output/marknotes/3300089819_marknotes.csv
  
  # æ ¹æ® bookId è¿‡æ»¤
  python import_marknotes_to_anki.py --book-id 3300089819
  
  # æ ¹æ®ä¹¦åè¿‡æ»¤
  python import_marknotes_to_anki.py --book-name "æç®€å¤®è¡Œè¯¾"
  
  # è‡ªåŠ¨ç”Ÿæˆ marknotes æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
  python import_marknotes_to_anki.py --book-name "æç®€å¤®è¡Œè¯¾" --auto-generate
  
  # å…ˆé‡æ–° fetch æ•°æ®ï¼Œå†è‡ªåŠ¨ç”Ÿæˆ marknotes
  python import_marknotes_to_anki.py --book-name "æç®€å¤®è¡Œè¯¾" --auto-generate --fetch
  
  # è¯•è¿è¡Œï¼ˆä¸å®é™…æ·»åŠ å¡ç‰‡ï¼‰
  python import_marknotes_to_anki.py --dry-run
  
  # æŒ‡å®š AnkiConnect åœ°å€
  python import_marknotes_to_anki.py --anki-url http://127.0.0.1:8765
  
  # æŒ‡å®šæ‰¹é‡å¤§å°
  python import_marknotes_to_anki.py --batch-size 50
        """
    )
    
    parser.add_argument('--file', '--csv-file', dest='csv_file', type=str, default=None,
                       help='è¦å¯¼å…¥çš„ marknotes CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™å¯¼å…¥æ‰€æœ‰ marknotes æ–‡ä»¶ï¼‰')
    
    # ä¹¦ç±è¿‡æ»¤å‚æ•°ï¼ˆäº’æ–¥ï¼‰
    book_group = parser.add_mutually_exclusive_group()
    book_group.add_argument('--book-id', '--id', dest='book_id', type=str, default=None,
                           help='ä¹¦ç±IDï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªå¯¼å…¥è¯¥ä¹¦ç±çš„ marknotes æ–‡ä»¶ï¼‰')
    book_group.add_argument('--book-name', '--book-title', dest='book_name', type=str, default=None,
                           help='ä¹¦ç±åç§°ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åªå¯¼å…¥è¯¥ä¹¦ç±çš„ marknotes æ–‡ä»¶ï¼‰')
    
    parser.add_argument('--anki-url', dest='anki_url', type=str, default=None,
                       help=f'AnkiConnect API åœ°å€ï¼ˆé»˜è®¤: {ANKI_CONNECT_URL}ï¼‰')
    parser.add_argument('--model', '--model-name', dest='model_name', type=str, default=None,
                       help=f'Anki å¡ç‰Œæ¨¡æ¿åç§°ï¼ˆé»˜è®¤: {ANKI_MODEL_NAME}ï¼‰')
    parser.add_argument('--dry-run', dest='dry_run', action='store_true',
                       help='è¯•è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…æ·»åŠ å¡ç‰‡')
    parser.add_argument('--sync', dest='sync', action='store_true',
                       help='å¯¼å…¥å®ŒæˆååŒæ­¥åˆ° AnkiWebï¼ˆå·²å¼ƒç”¨ï¼šç°åœ¨æ€»æ˜¯ä¼šè‡ªåŠ¨åŒæ­¥ï¼‰')
    parser.add_argument('--auto-generate', dest='auto_generate', action='store_true',
                       help='å¦‚æœæ‰¾ä¸åˆ° marknotes æ–‡ä»¶ï¼Œè‡ªåŠ¨è°ƒç”¨ generate_marknotes.py ç”Ÿæˆ')
    parser.add_argument('--fetch', '--refresh-data', dest='fetch_data', action='store_true',
                       help='åœ¨ç”Ÿæˆ marknotes ä¹‹å‰ï¼Œå…ˆé‡æ–° fetch ç¬”è®°æ•°æ®ï¼ˆéœ€è¦ --auto-generateï¼‰')
    parser.add_argument('--api-key', dest='api_key', type=str, default=None,
                       help='Gemini API å¯†é’¥ï¼ˆç”¨äºè‡ªåŠ¨ç”Ÿæˆ marknotesï¼Œä¼˜å…ˆä»ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEY è¯»å–ï¼‰')
    parser.add_argument('--batch-size', dest='batch_size', type=int, default=100,
                       help='æ‰¹é‡æ·»åŠ å¡ç‰‡çš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤: 100ï¼Œå»ºè®®èŒƒå›´: 10-200ï¼‰')
    
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº† --fetch ä½†æ²¡æœ‰ --auto-generateï¼Œæç¤ºç”¨æˆ·
    if args.fetch_data and not args.auto_generate:
        print("âš ï¸  è­¦å‘Šï¼š--fetch å‚æ•°éœ€è¦é…åˆ --auto-generate ä½¿ç”¨")
        print("   å°†è‡ªåŠ¨å¯ç”¨ --auto-generate")
        args.auto_generate = True
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = Path(__file__).parent  # anki/scripts
    project_root = script_dir.parent.parent  # é¡¹ç›®æ ¹ç›®å½•
    
    # é»˜è®¤ marknotes ç›®å½•
    marknotes_dir = project_root / "llm" / "output" / "marknotes"
    
    # åˆå§‹åŒ– AnkiConnect å®¢æˆ·ç«¯
    anki_url = args.anki_url or ANKI_CONNECT_URL
    try:
        anki_client = AnkiConnectClient(url=anki_url)
        # æµ‹è¯•è¿æ¥
        anki_client._invoke("version")
        print(f"âœ“ æˆåŠŸè¿æ¥åˆ° AnkiConnect ({anki_url})")
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ° AnkiConnect: {e}")
        print(f"\nè¿æ¥åœ°å€: {anki_url}")
        print("\nè¯·ç¡®ä¿ï¼š")
        print("  1. Anki æ­£åœ¨è¿è¡Œ")
        print("  2. å·²å®‰è£… AnkiConnect æ’ä»¶")
        print(f"  3. AnkiConnect é…ç½®æ­£ç¡®ï¼ˆå½“å‰åœ°å€: {anki_url}ï¼‰")
        return
    
    # ç¡®å®šè¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
    csv_files = []
    target_book_id = None
    
    if args.csv_file:
        # å¦‚æœæŒ‡å®šäº†æ–‡ä»¶ï¼Œåªå¤„ç†è¯¥æ–‡ä»¶
        csv_file = Path(args.csv_file)
        if not csv_file.is_absolute():
            csv_file = project_root / csv_file
        if csv_file.exists():
            csv_files = [csv_file]
        else:
            print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨: {csv_file}")
            return
    else:
        # å¦åˆ™å¤„ç†æ‰€æœ‰ marknotes æ–‡ä»¶
        if not marknotes_dir.exists():
            print(f"âŒ é”™è¯¯ï¼šç›®å½•ä¸å­˜åœ¨: {marknotes_dir}")
            return
        
        # è·å–æ‰€æœ‰ marknotes CSV æ–‡ä»¶
        all_csv_files = list(marknotes_dir.glob("*_marknotes.csv"))
        
        if args.book_id:
            target_book_id = args.book_id
            print(f"è¿‡æ»¤æ¡ä»¶ï¼šbookId = {target_book_id}")
        elif args.book_name:
            # ä» fetch_notebooks_output.csv ä¸­æŸ¥æ‰¾ bookId
            notebooks_csv = project_root / "wereader" / "output" / "fetch_notebooks_output.csv"
            if notebooks_csv.exists():
                target_book_id = find_book_id_by_title(notebooks_csv, args.book_name)
                if target_book_id:
                    print(f"æ‰¾åˆ°ä¹¦ç±ï¼š{args.book_name} (bookId: {target_book_id})")
                else:
                    print(f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä¹¦å '{args.book_name}' å¯¹åº”çš„ bookId")
                    return
            else:
                print(f"âŒ é”™è¯¯ï¼šæ— æ³•æŸ¥æ‰¾ä¹¦åï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {notebooks_csv}")
                return
        
        if target_book_id:
            # æ ¹æ® bookId è¿‡æ»¤æ–‡ä»¶ï¼ˆæ–‡ä»¶åæ ¼å¼ï¼š{bookId}_marknotes.csvï¼‰
            target_file = marknotes_dir / f"{target_book_id}_marknotes.csv"
            
            # å¦‚æœæŒ‡å®šäº† --fetchï¼Œå³ä½¿æ–‡ä»¶å­˜åœ¨ä¹Ÿè¦é‡æ–°ç”Ÿæˆ
            if args.fetch_data and args.auto_generate:
                print(f"\nğŸ”„ æ£€æµ‹åˆ° --fetch å‚æ•°ï¼Œå°†å…ˆé‡æ–° fetch æ•°æ®å¹¶ç”Ÿæˆ marknotes...")
                if generate_marknotes is None:
                    print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ generate_marknotes æ¨¡å—ï¼Œæ— æ³•é‡æ–°ç”Ÿæˆ marknotes")
                    print(f"è¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡æ–°ç”Ÿæˆ marknotesï¼š")
                    if args.book_name:
                        print(f"  python llm/scripts/generate_marknotes.py --book-name \"{args.book_name}\" --fetch")
                    else:
                        print(f"  python llm/scripts/generate_marknotes.py --book-id {target_book_id} --fetch")
                    return
                
                print(f"\nğŸ”„ æ­£åœ¨é‡æ–°ç”Ÿæˆ marknotes CSV æ–‡ä»¶ï¼ˆä½¿ç”¨æœ€æ–°æ•°æ®ï¼‰...")
                try:
                    api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                    if not api_key:
                        print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                        print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                        return
                    
                    # ä¼ é€’ book_name ä»¥ç¡®ä¿ fetch æ—¶èƒ½æ­£ç¡®ä½¿ç”¨ä¹¦å
                    generate_marknotes(book_id=target_book_id, book_title=args.book_name if args.book_name else None, api_key=api_key, fetch_data=True)
                    
                    # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                    if target_file.exists():
                        csv_files.append(target_file)
                        print(f"âœ“ æˆåŠŸé‡æ–°ç”Ÿæˆ marknotes CSV æ–‡ä»¶")
                    else:
                        print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                        return
                except Exception as e:
                    print(f"âŒ é‡æ–°ç”Ÿæˆ marknotes å¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
                    return
            elif target_file.exists():
                csv_files.append(target_file)
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ° bookId '{target_book_id}' å¯¹åº”çš„ marknotes CSV æ–‡ä»¶")
                # å¦‚æœå¯ç”¨äº†è‡ªåŠ¨ç”Ÿæˆï¼Œå°è¯•ç”Ÿæˆ
                if args.auto_generate:
                    if generate_marknotes is None:
                        print(f"\nâŒ é”™è¯¯ï¼šæ— æ³•å¯¼å…¥ generate_marknotes æ¨¡å—ï¼Œæ— æ³•è‡ªåŠ¨ç”Ÿæˆ marknotes")
                        print(f"è¯·æ‰‹åŠ¨è¿è¡Œä»¥ä¸‹å‘½ä»¤ç”Ÿæˆ marknotesï¼š")
                        if args.book_name:
                            print(f"  python llm/scripts/generate_marknotes.py --book-name \"{args.book_name}\"")
                        else:
                            print(f"  python llm/scripts/generate_marknotes.py --book-id {target_book_id}")
                        return
                    
                    print(f"\nğŸ”„ æ­£åœ¨è‡ªåŠ¨ç”Ÿæˆ marknotes CSV æ–‡ä»¶...")
                    try:
                        api_key = args.api_key or os.environ.get('GOOGLE_API_KEY') or os.environ.get('GEMINI_API_KEY')
                        if not api_key:
                            print(f"âŒ é”™è¯¯ï¼šæœªè®¾ç½® Gemini API å¯†é’¥")
                            print(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY æˆ– GOOGLE_API_KEYï¼Œæˆ–ä½¿ç”¨ --api-key å‚æ•°")
                            return
                        
                        # å¦‚æœæŒ‡å®šäº† --fetchï¼Œä¼ é€’ fetch_data=Trueï¼ŒåŒæ—¶ä¼ é€’ book_name ä»¥ç¡®ä¿ fetch æ—¶èƒ½æ­£ç¡®ä½¿ç”¨ä¹¦å
                        generate_marknotes(book_id=target_book_id, book_title=args.book_name if args.book_name else None, api_key=api_key, fetch_data=args.fetch_data)
                        
                        # é‡æ–°æ£€æŸ¥æ–‡ä»¶
                        if target_file.exists():
                            csv_files.append(target_file)
                            print(f"âœ“ æˆåŠŸç”Ÿæˆ marknotes CSV æ–‡ä»¶")
                        else:
                            print(f"âš ï¸  ç”Ÿæˆå®Œæˆï¼Œä½†æœªæ‰¾åˆ°å¯¹åº”çš„ CSV æ–‡ä»¶")
                            return
                    except Exception as e:
                        print(f"âŒ è‡ªåŠ¨ç”Ÿæˆ marknotes å¤±è´¥: {e}")
                        import traceback
                        traceback.print_exc()
                        return
                else:
                    print(f"\næç¤ºï¼šå¯ä»¥ä½¿ç”¨ --auto-generate å‚æ•°è‡ªåŠ¨ç”Ÿæˆï¼š")
                    print(f"  python anki/scripts/import_marknotes_to_anki.py --book-name \"{args.book_name}\" --auto-generate")
                    return
        else:
            # å¤„ç†æ‰€æœ‰æ–‡ä»¶
            csv_files = all_csv_files
    
    if not csv_files:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„ CSV æ–‡ä»¶")
        return
    
    print(f"\næ‰¾åˆ° {len(csv_files)} ä¸ª CSV æ–‡ä»¶éœ€è¦å¤„ç†")
    
    # å¤„ç†æ¯ä¸ª CSV æ–‡ä»¶
    for csv_file in csv_files:
        try:
            import_csv_to_anki(
                csv_file=csv_file,
                anki_client=anki_client,
                model_name=args.model_name,
                dry_run=args.dry_run,
                sync=args.sync,
                batch_size=args.batch_size
            )
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {csv_file.name} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"\n{'='*60}")
    print("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ")
    print(f"{'='*60}")
    
    # æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆåï¼Œå¼ºåˆ¶åŒæ­¥åˆ° AnkiWeb
    if not args.dry_run:
        print(f"\næ­£åœ¨åŒæ­¥åˆ° AnkiWeb...")
        if anki_client.sync():
            print(f"âœ“ åŒæ­¥æˆåŠŸ")
        else:
            print(f"âš ï¸  åŒæ­¥å¤±è´¥ï¼Œè¯·ç¨åæ‰‹åŠ¨åŒæ­¥")


if __name__ == "__main__":
    main()
